# 프로젝트 소개

## 1. 개발배경 및 필요성
이 스터디는 머신러닝에 관심이 있는 저학년 학부생들의 학업 증진을 위한 스터디입니다.

## 2. 개발목표 및 주요내용
- 기본적인 컴퓨터의 머신러닝 과정을 이해합니다.
- 이론적인 공부를 통해 데이터셋에 대한 더 나은 모델 선택 및 전처리 기법을 탐구합니다.
- 배운 이론을 Kaggle 사이트의 데이터셋에 적용하여 분류 작업을 수행합니다.

### 사용 데이터셋
- Kaggle Titanic 데이터셋: [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)

---

# 상세설계

## 1. 시스템 구성도

### 데이터 분석
1. Pandas 라이브러리를 활용한 데이터셋 다루기 및 분석
   - 상관관계 분석
   - 시각화 함수 활용

### 머신러닝 모델 학습
- 공부할 모델 목록:
  - 단일 퍼셉트론
  - 아달린
  - 로지스틱 회귀
  - SVM (커널 SVM 포함)
  - 결정 트리
  - 랜덤 포레스트

### 데이터 전처리
1. 결측치 처리
   - 결측치 제거
   - 결측치 대체 (평균값, 중간값 등으로 채우기)
2. 인코딩
   - 라벨 인코딩
   - 원핫 인코딩

### 모델 파라미터 튜닝
1. 각 모델별 파라미터 정리
2. GridSearch를 통한 최적의 파라미터 탐색

### 모델 평가
1. 분산과 편향 분석
2. 검증 데이터셋을 활용한 모델의 일반화 평가

### 앙상블 학습
1. 모델 간 평가 기준 학습
2. 다수결 투표 방식의 앙상블 기법 활용

---

# 개발결과

## 1. 전체 시스템 흐름도

### 데이터 관측 및 분석
- Jupyter Notebook 및 Pandas DataFrame 활용
- 상관관계 계수 행렬 생성 및 시각화
- 데이터 분석 예시:
  - 연령대별 생존률을 분석 (10명 단위로 그룹화)

### 모델 학습 과정
1. 선형 데이터셋
   - 퍼셉트론: 손실 함수 없이 가중치 학습
   - 아달린: 손실 함수 기반 가중치 학습
   - 로지스틱 회귀: 확률 기반 레이블 예측
2. 비선형 데이터셋
   - 커널 SVM, 결정 트리, 랜덤 포레스트

### 편향과 분산
- 편향과 분산 개념 이론 소개
- 분류 라인 시각화를 통해 이론 학습

### 하이퍼파라미터 튜닝
- 모델의 하이퍼파라미터 설정 및 분산 제어 방법 소개

### 데이터 전처리
1. 결측치 처리
   - 결측치 제거
   - 평균값 대체
2. 인코딩
   - 원핫 인코딩
   - 라벨 인코딩

### 모델 훈련
- GridSearch를 활용한 최적 파라미터 탐색

---

# 팀 소개

- **정유성**: 정보컴퓨터공학과 컴퓨터공학전공 (멘토, 팀원)
- **이예람**: 정보컴퓨터공학과 인공지능전공 (멘티, 팀장)
- **박지원**: 정보컴퓨터공학과 인공지능전공 (멘티, 팀원)
- **정민혁**: 정보컴퓨터공학과 인공지능전공 (멘티, 팀원)
- **최지훈**: 정보컴퓨터공학과 인공지능전공 (멘티, 팀원)
